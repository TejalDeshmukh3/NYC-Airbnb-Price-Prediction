{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380ef64e-4cd2-4842-a145-8f4acbeb0dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    " \n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "#For evaluation\n",
    "from sklearn.metrics import mean_squared_log_error as msle\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0382eb-8d83-4f1a-8475-a8af1ab15608",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('airbnb.csv', low_memory=False)\n",
    "print(df.shape)\n",
    "df.dtypes\n",
    "airbnb = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9a98ae-294d-4236-abea-f8b42604a5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb.head()\n",
    "airbnb = airbnb.loc[airbnb.city == 'NYC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4d82ac-d4a4-4483-9b69-3af0c937cf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop bad rows with 0 in important features\n",
    "airbnb = airbnb.loc[airbnb.beds * airbnb.accommodates * airbnb.bathrooms * airbnb.bedrooms != 0]\n",
    "# Drop those with bad target variable values\n",
    "airbnb = airbnb.loc[airbnb.log_price > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf90f610-01ce-490e-9b30-cc10f313460c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning dataset columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba40defc-67e0-453d-920d-d4f58a493ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns that will not be helpful for price prediction\n",
    "airbnb.drop(['id','description','host_has_profile_pic','name','thumbnail_url','first_review','host_since','last_review','city','zipcode','host_response_rate'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6e35ca-ef15-444a-95f0-1a20c5dc48a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check correlation to keep right features\n",
    "corrs = airbnb.corr()\n",
    "plt.subplots(figsize=(8,6))\n",
    "sns.heatmap(corrs, vmax=0.8, square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b4ed04-722f-4752-ad90-b0cc2a5eb9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check nulls\n",
    "airbnb.isnull().sum()\n",
    "# Drop review_scores_rating as it has too many nulls\n",
    "airbnb.drop(['review_scores_rating'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb0c2e6-b960-4925-a1de-c9d04fe1857a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill remaining nulls for baths with mean value\n",
    "airbnb['bathrooms'].fillna((airbnb['bathrooms'].mean()), inplace=True)\n",
    "airbnb.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cd3f66-1a27-4884-b1c2-cf71aafe40db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove those listings with unknown neighbourhood\n",
    "airbnb.dropna(subset=['neighbourhood'], inplace=True)\n",
    "airbnb.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60f656a-5f8b-43d9-a2f3-03a04e26b346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill bedrooms with 0 for nulls\n",
    "airbnb['beds'] = airbnb['beds'].fillna(0)\n",
    "airbnb['bedrooms'] = airbnb['bedrooms'].fillna(0)\n",
    "airbnb.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70269d7-08fd-4221-9694-b9239a7a35c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7a1d29-7b58-47d5-b3cc-f1aca905c83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert binary categories to vals\n",
    "airbnb.cleaning_fee = airbnb.cleaning_fee.astype('category').cat.codes\n",
    "airbnb.host_identity_verified = airbnb.host_identity_verified.astype('category').cat.codes\n",
    "airbnb.instant_bookable = airbnb.instant_bookable.astype('category').cat.codes\n",
    "# Make sure there are no more nulls\n",
    "airbnb.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969d1579-7c6b-4ead-9fa9-69ee02170159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retain 1 DF with the categoricals for any model that may require them\n",
    "# Convert room_type categorical\n",
    "airbnb.room_type.value_counts()\n",
    "room_dummies = pd.get_dummies(airbnb.room_type,prefix='room').iloc[:,1:]\n",
    "airbnb_dummies = pd.concat([airbnb,room_dummies],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ca86bb-7493-405d-8292-db54e659e811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the originals\n",
    "airbnb.drop(['room_type'],axis=1,inplace=True)\n",
    "airbnb_dummies.drop(['room_type'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe7a81d-3ad3-4302-a655-3e11744c3515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert property_type categorical\n",
    "airbnb.property_type.value_counts()\n",
    "# Based on value counts, change property_type into 5 categories and create dummies \n",
    "property_type_map = {'Apartment':['Condominium','Loft','Serviced apartment','Guest suite'],\n",
    "         'House':['Vacation home','Villa','Townhouse','In-law','Casa particular'],\n",
    "         'Hostel':['Dorm','Hostel','Guesthouse'],\n",
    "         'Hotel':['Boutique hotel','Bed & Breakfast'],\n",
    "         'Timeshare':['Timeshare'],\n",
    "         'Other':['Island','Castle','Yurt','Hut','Chalet','Treehouse',\n",
    "                  'Earth House','Tipi','Cave','Train','Parking Space','Lighthouse',\n",
    "                 'Tent','Boat','Cabin','Camper/RV','Bungalow']\n",
    "        }\n",
    "property_type_group = {i : k for k, v in property_type_map.items() for i in v}\n",
    "airbnb['property_group'] = airbnb['property_type'].replace(property_type_group)\n",
    "airbnb.drop('property_type',axis=1,inplace=True)\n",
    "# Convert to dummies\n",
    "airbnb_dummies['property_group'] = airbnb_dummies['property_type'].replace(property_type_group)\n",
    "property_dummies = pd.get_dummies(airbnb_dummies.property_group,prefix='property').iloc[:,1:]\n",
    "airbnb_dummies = pd.concat([airbnb_dummies,property_dummies],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf56c64-61e4-447e-8fc4-452824243a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the originals\n",
    "airbnb_dummies.drop('property_type',axis=1,inplace=True)\n",
    "airbnb_dummies.drop('property_group',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53abcd6f-312b-460a-a514-ef66f3d46daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check cancellation policy\n",
    "airbnb.cancellation_policy.value_counts()\n",
    "# Based on value counts, ignore 30, 60 as they are negligible\n",
    "airbnb = airbnb[airbnb.cancellation_policy != ('super_strict_30')]\n",
    "airbnb = airbnb[airbnb.cancellation_policy != ('super_strict_60')]\n",
    "airbnb_dummies = airbnb_dummies[airbnb_dummies.cancellation_policy != ('super_strict_30')]\n",
    "airbnb_dummies = airbnb_dummies[airbnb_dummies.cancellation_policy != ('super_strict_60')]\n",
    "# Convert rest to dummies\n",
    "cancellation_dummies = pd.get_dummies(airbnb_dummies.cancellation_policy,prefix='cancellation').iloc[:,1:]\n",
    "airbnb_dummies = pd.concat([airbnb_dummies,cancellation_dummies],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a61f3d-7e92-4013-a720-5f19942a9827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the original\n",
    "airbnb_dummies.drop('cancellation_policy',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1961ca-50d9-4c92-be1a-3a4c8bd98ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert bed_type categorical\n",
    "airbnb.bed_type.value_counts()\n",
    "# Change to binary - real bed or not\n",
    "def bed_type_func(row):\n",
    "  if row.loc['bed_type'] == 'Real Bed':\n",
    "    return 1\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "airbnb['real_bed'] = airbnb.apply(bed_type_func, axis=1)\n",
    "airbnb.drop('bed_type',axis=1,inplace=True)\n",
    "airbnb_dummies['real_bed'] = airbnb_dummies.apply(bed_type_func, axis=1)\n",
    "airbnb_dummies.drop('bed_type',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccba0cf-3860-4968-8905-56c4976804f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use lat, long to find distance to prime locations such as times square, train station\n",
    "airbnb['latitude_north'] = (airbnb.latitude - airbnb.latitude.min()) / (airbnb.latitude.max() - airbnb.latitude.min())\n",
    "airbnb['longitude_east'] = (airbnb.longitude - airbnb.longitude.min()) / (airbnb.longitude.max() - airbnb.longitude.min())\n",
    "airbnb_dummies['latitude_north'] = (airbnb_dummies.latitude - airbnb_dummies.latitude.min()) / (airbnb_dummies.latitude.max() - airbnb_dummies.latitude.min())\n",
    "airbnb_dummies['longitude_east'] = (airbnb_dummies.longitude - airbnb_dummies.longitude.min()) / (airbnb_dummies.longitude.max() - airbnb_dummies.longitude.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3e7b63-2c81-4a42-80a7-d6668d1ebbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb['dist_t_squre'] = np.sqrt((40.758896-airbnb['latitude'])**2+(-73.985130-airbnb['longitude'])**2)\n",
    "airbnb['dist_gc_train'] = np.sqrt((40.752655-airbnb['latitude'])**2+(-73.977295-airbnb['longitude'])**2)\n",
    "airbnb['dist_w_street']=np.sqrt((40.706005-airbnb['latitude'])**2+(-74.008827-airbnb['longitude'])**2)\n",
    "\n",
    "airbnb_dummies['dist_t_squre'] = np.sqrt((40.758896-airbnb_dummies['latitude'])**2+(-73.985130-airbnb_dummies['longitude'])**2)\n",
    "airbnb_dummies['dist_gc_train'] = np.sqrt((40.752655-airbnb_dummies['latitude'])**2+(-73.977295-airbnb_dummies['longitude'])**2)\n",
    "airbnb_dummies['dist_w_street']=np.sqrt((40.706005-airbnb_dummies['latitude'])**2+(-74.008827-airbnb_dummies['longitude'])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c60c6c-13e4-4f73-a589-17c3cb703fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop originals\n",
    "airbnb.drop(['latitude','longitude'],axis=1,inplace=True)\n",
    "airbnb_dummies.drop(['latitude','longitude'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2b63fb-9f6e-45b5-8e6f-cc874bf76c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use neighbuorhood to create levels based on cost per room\n",
    "airbnb['price_per_room'] = airbnb['log_price'] / airbnb['bedrooms']\n",
    "nhood_avg_price = airbnb[['neighbourhood','price_per_room']].groupby('neighbourhood')['price_per_room'].mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d12d39d-d3b8-4177-a496-865a61ca58eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nhood_avg_price.replace(np.inf, np.nan,inplace=True)\n",
    "nhood_avg_price.fillna(nhood_avg_price.mean(),inplace=True)\n",
    "nhood_class_df = nhood_avg_price.to_frame()\n",
    "def neigbourhood_class(row):\n",
    "  if row['price_per_room'] >=0 and row['price_per_room'] <= 3.683610:\n",
    "    return 1\n",
    "  elif row['price_per_room'] > 3.6836100 and row['price_per_room'] <= 3.868928:\n",
    "    return 2\n",
    "  elif row['price_per_room'] >3.868928 and row['price_per_room'] <= 4.194452: \n",
    "    return 3\n",
    "  else:\n",
    "    return 4\n",
    "  \n",
    "nhood_class_df['neigbourhood_level'] = nhood_class_df.apply(neigbourhood_class,axis=1)\n",
    "nhood_class_df.drop('price_per_room',axis=1,inplace=True)\n",
    "airbnb = airbnb.join(nhood_class_df,on='neighbourhood')\n",
    "airbnb_dummies = airbnb_dummies.join(nhood_class_df,on='neighbourhood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37069ed2-8f90-4519-be80-247e78f6b6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop neighborhood originals\n",
    "airbnb.drop(['neighbourhood'],axis=1,inplace=True)\n",
    "airbnb_dummies.drop(['neighbourhood'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcc8d58-94c6-45be-acd2-426d2d61526c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.scatter(airbnb, x='longitude', y='latitude',\n",
    "                 color='neigbourhood_level', width=800, height=600) # Added color to previous basic \n",
    "fig.update_layout(xaxis_title=\"longitude\",yaxis_title=\"latitude\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a3b806-a1a0-40e9-b0f6-347663da43e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle list of amenities\n",
    "l=list(airbnb['amenities'])\n",
    "l=[[word.strip('[\" ]') for word in row[1:-1].split(',')] for row in list(airbnb['amenities'])]\n",
    "cols = set(word for row in l  for word in row)\n",
    "amenities_df=pd.DataFrame(columns=cols)\n",
    "print(cols)\n",
    "amenities_df = pd.DataFrame(columns=cols)\n",
    "for row_idx in range(len(l)):\n",
    "    for col in cols:\n",
    "        amenities_df.loc[row_idx,col]=int(col in l[row_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d4aa48-7af0-4c2d-a38d-926d1196546d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group together the similar ones\n",
    "amenities_group_df = pd.DataFrame()\n",
    "amenities_group_df['kitchen'] = amenities_df['Kitchen']+amenities_df['Breakfast']+amenities_df['Cooking basics']+amenities_df['Cooking basics']+amenities_df['BBQ grill']+amenities_df['Oven']+amenities_df['Coffee maker']+amenities_df['Microwave']+amenities_df['Refrigerator']+amenities_df['Dishwasher']\n",
    "amenities_group_df['accesibility'] = amenities_df['Free parking on premises']+amenities_df['Wide clearance to bed']+amenities_df['smooth pathway to front door']+amenities_df['Ground floor access']+amenities_df['Lake access']+amenities_df['Wheelchair accessible']+amenities_df['Wide clearance to shower & toilet']+amenities_df['Wide hallway clearance']+amenities_df['Wide doorway']+amenities_df['Accessible-height toilet']+amenities_df['Step-free access']+amenities_df['Well-lit path to entrance']+amenities_df['Waterfront']+amenities_df['Free parking on street']+amenities_df['Disabled parking spot']+amenities_df['Accessible-height bed']+amenities_df['Private entrance']+amenities_df['Elevator']\n",
    "amenities_group_df['electric_tech'] = amenities_df['Wide entryway']+amenities_df['Air conditioning']+amenities_df['Ethernet connection']+amenities_df['Cable TV']+amenities_df['Internet']+amenities_df['EV charger']+amenities_df['Baby monitor']+amenities_df['TV']+amenities_df['Wireless Internet']+amenities_df['Pocket wifi']+amenities_df['Washer']+amenities_df['Dryer']+amenities_df['Keypad']+amenities_df['Game console']+amenities_df['Washer / Dryer']+amenities_df['Hair dryer']\n",
    "amenities_group_df['facilities'] = amenities_df['Private living room']+amenities_df['Air purifier']+amenities_df['Handheld shower head']+amenities_df['Hot water kettle']+amenities_df['Extra pillows and blankets']+amenities_df['Hot tub']+amenities_df['Pets live on this property']+amenities_df['Heating']+amenities_df['Dishes and silverware']+amenities_df['Patio or balcony']+amenities_df['Bed linens']+amenities_df['First aid kit']+amenities_df['Crib']+amenities_df['Flat']+amenities_df['Laptop friendly workspace']+amenities_df['Buzzer/wireless intercom']+amenities_df['Firm mattress']+amenities_df['Iron']+amenities_df['Changing table']+amenities_df['Hangers']+amenities_df['Roll-in shower with chair']+amenities_df['Gym']+amenities_df['Outlet covers']+amenities_df['Essentials']+amenities_df['Private bathroom']+amenities_df['Baby bath']+amenities_df['Bathtub']+amenities_df['Shampoo']+amenities_df['Beachfront']+amenities_df['Single level home']+amenities_df['Hot water']+amenities_df['High chair']+amenities_df['Bathtub with shower chair']+amenities_df['Pool']+amenities_df['Fixed grab bars for shower & toilet']+amenities_df['Room-darkening shades']+amenities_df['Beach essentials']+amenities_df['Garden or backyard']\n",
    "amenities_group_df['kids_friendly'] = amenities_df['Babysitter recommendations']+amenities_df['Family/kid friendly']+amenities_df['Children’s books and toys']+amenities_df['Children’s dinnerware']\n",
    "amenities_group_df['security'] = amenities_df['Window guards']+amenities_df['Stair gates']+amenities_df['Fireplace guards']+amenities_df['Doorman']+amenities_df['Carbon monoxide detector']+amenities_df['Smoke detector']+amenities_df['Table corner guards']+amenities_df['Fire extinguisher']+amenities_df['Lock on bedroom door']+amenities_df['Smart lock']+amenities_df['Lockbox']\n",
    "amenities_group_df['services'] = amenities_df['Ski in/Ski out']+amenities_df['Cleaning before checkout']+amenities_df['Long term stays allowed']+amenities_df['Other pet(s)']+amenities_df['Cat(s)']+amenities_df['Self Check-In']+amenities_df['24-hour check-in']+amenities_df['Host greets you']+amenities_df['Luggage dropoff allowed']+amenities_df['Pack ’n Play/travel crib']+amenities_df['Pets allowed']+amenities_df['Suitable for events']+amenities_df['Safety card']+amenities_df['Indoor fireplace']+amenities_df['Dog(s)']+amenities_df['Smoking allowed']\n",
    "amenities_group_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8b5615-965c-4a9e-a88a-3d45d09ae218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join it to original data\n",
    "airbnb['join_key'] = range(0,len(airbnb))\n",
    "airbnb.index = airbnb['join_key']\n",
    "airbnb_cleaned = airbnb.join(amenities_group_df)\n",
    "airbnb_dummies['join_key'] = range(0,len(airbnb_dummies))\n",
    "airbnb_dummies.index = airbnb_dummies['join_key']\n",
    "airbnb_dummies_cleaned = airbnb_dummies.join(amenities_group_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e067b45-a261-4a70-bd94-1e682bc78621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the originals\n",
    "airbnb_cleaned.drop(['amenities'],axis=1,inplace=True)\n",
    "airbnb_dummies_cleaned.drop(['amenities'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e236ea-0ef5-4a54-b708-d5b36a181728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying sentiment analysis\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "# Read the separated description data from other file\n",
    "df = pd.read_csv('train.csv')\n",
    "df.shape\n",
    "df[\"description\"].value_counts()\n",
    "df.loc[df[\"description\"] == \"\"]\n",
    "\n",
    "#Clean and process texts\n",
    "from nltk.corpus import stopwords\n",
    "stopwords_list = set(stopwords.words(\"english\"))\n",
    "punctuations = \"\"\"!()-![]{};:,+'\"\\,<>./?@#$%^&*_~Â\"\"\" #List of punctuation to remove\n",
    "\n",
    "def descriptionParse(description):\n",
    "    splitDescription = description.split() #Split the description into words\n",
    "    parsedDescription = \" \".join([word.translate(str.maketrans('', '', punctuations)) + \" \" for word in splitDescription]) #Takes the stubborn punctuation out\n",
    "    return parsedDescription #Returns the parsed description\n",
    "  \n",
    "def clean_description(description):\n",
    "    clean_words = []\n",
    "    splitReview = description.split()\n",
    "    for w in splitdescription:\n",
    "        if w.isalpha() and w not in stopwords_list:\n",
    "            clean_words.append(w.lower())\n",
    "    clean_description = \" \".join(clean_words)\n",
    "    return clean_description\n",
    "\n",
    "df[\"description\"] = df[\"description\"].apply(descriptionParse).apply(clean_description) #Parse all the description for their punctuation and add it into a new column\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    " \n",
    "docs = list(df['description'])[:7000]\n",
    "# settings that you use for count vectorizer will go here \n",
    "tfidf_vectorizer=TfidfVectorizer(use_idf=True, max_features = 20000) \n",
    " \n",
    "# just send in all your docs here \n",
    "tfidf_vectorizer_vectors=tfidf_vectorizer.fit_transform(docs)\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "df['rating'] = tfidf_vectorizer_vectors.apply(lambda x: analyzer.polarity_scores(x))\n",
    "df.tail(3)\n",
    "\n",
    "df['sentiment'] = df['rating'].apply(lambda x: 'positive' if x >0 else 'neutral' if x==0 else 'negative')\n",
    "df.head(4)\n",
    "\n",
    "def sentiment(rating):\n",
    "  if rating == 'positive':\n",
    "    return 2\n",
    "  elif rating == 'negative':\n",
    "    return 0\n",
    "  else:\n",
    "    return 1  \n",
    "df['sentiment'] = df['description'].apply(sentiment)\n",
    "\n",
    "# Mostly 1's & didn't improve model performance when combined with airbnb_dummies,leave out for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e7f04c-4d24-4162-8178-c439dc13feb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify before fitting model\n",
    "airbnb_dummies_cleaned.isnull().sum()\n",
    "airbnb_dummies_cleaned.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfcb67e-609b-4de7-a183-2b0b653c1b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for model\n",
    "# Splitting the data to X and y\n",
    "X = airbnb_dummies_cleaned.drop('log_price', axis=1)\n",
    "y = airbnb_dummies_cleaned.log_price\n",
    "\n",
    "# Splitting data to train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,train_size=0.8,random_state=700)\n",
    "\n",
    "# With scaler\n",
    "scaler = StandardScaler() \n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dded7123-714b-4865-b606-f1857ba58c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression\n",
    "linear_model_1 = LinearRegression()\n",
    "linear_model_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b623b9f-0a97-4362-9174-c57c4c40f6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "y_test_predm1 = linear_model_1.predict(X_test)\n",
    "y_train_predm1 = linear_model_1.predict(X_train)\n",
    "print(\"Training MSE:\", round(mean_squared_error(y_train, y_train_predm1),4))\n",
    "print(\"Validation MSE:\", round(mean_squared_error(y_test, y_test_predm1),4))\n",
    "print(\"\\nTraining r2:\", round(r2_score(y_train, y_train_predm1),4))\n",
    "print(\"Validation r2:\", round(r2_score(y_test, y_test_predm1),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a213043-cea1-4cde-a8b8-9d8355d21ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(x=y_test, y=y_test_predm1)\n",
    "ax.plot(y_test, y_test, 'r')\n",
    "ax.set(title='Actual vs Predicted price linear regression')\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956d3f33-4578-4ebb-a669-a834968c409e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso model\n",
    "from sklearn.linear_model import Lasso\n",
    "alpha = np.linspace(0.01,0.4,10)\n",
    "lasso = Lasso(alpha = alpha[i])\n",
    "lasso.fit(X_train,y_train)\n",
    "y_train_predm2 = lasso.predict(X_train)\n",
    "y_test_predm2 = lasso.predict(X_test)\n",
    "    print(\"Training MSE:\", round(mean_squared_error(y_train, y_train_predm2),4))\n",
    "    print(\"Validation MSE:\", round(mean_squared_error(y_test, y_test_predm2),4))\n",
    "    print(\"\\nTraining r2:\", round(r2_score(y_train, y_train_predm2),4))\n",
    "    print(\"Validation r2:\", round(r2_score(y_test, y_test_predm2),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78104607-a91e-4acc-91d2-5f233207fac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(x=y_test, y=y_test_predm1)\n",
    "ax.plot(y_test, y_test, 'r')\n",
    "ax.set(title='Actual vs Predicted price Lasso regression')\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f21be5-23a4-4bcf-8259-136db9723c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForest, GradientBoosting\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# Running model random forest\n",
    "rfm = RandomForestRegressor(\n",
    "          max_depth = 10,\n",
    "          n_jobs = -1, \n",
    "          n_estimators = 10\n",
    ")\n",
    "\n",
    "# Fit the model on training data\n",
    "rfm.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_train_predm2 = rfm.predict(X_train)\n",
    "\n",
    "# Validate\n",
    "y_test_predm2 = rfm.predict(X_test)\n",
    "\n",
    "print(\"Training MSE:\", round(mean_squared_error(y_train, y_train_predm2),4))\n",
    "print(\"Validation MSE:\", round(mean_squared_error(y_test, y_test_predm2),4))\n",
    "print(\"\\nTraining r2:\", round(r2_score(y_train, y_train_predm2),4))\n",
    "print(\"Validation r2:\", round(r2_score(y_test, y_test_predm2),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7c03dc-0604-4be3-9e04-8918d93685f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(x=y_test, y=y_test_predm2)\n",
    "ax.plot(y_test, y_test, 'r')\n",
    "ax.set(title='Actual vs Predicted price Random Forest')\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bbd1e4-0a0f-4662-92ac-e9305b0dcb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running model Gradient boosting\n",
    "gbr = GradientBoostingRegressor()\n",
    "\n",
    "# Fit the model on training data\n",
    "gbr.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_train_predm3 = gbr.predict(X_train)\n",
    "\n",
    "# Validate\n",
    "y_test_predm3 = gbr.predict(X_test)\n",
    "\n",
    "print(\"Training MSE:\", round(mean_squared_error(y_train, y_train_predm3),4))\n",
    "print(\"Validation MSE:\", round(mean_squared_error(y_test, y_test_predm3),4))\n",
    "print(\"\\nTraining r2:\", round(r2_score(y_train, y_train_predm3),4))\n",
    "print(\"Validation r2:\", round(r2_score(y_test, y_test_predm3),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b205706d-4d06-43cd-8a68-7bd6c60fc70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(x=y_test, y=y_test_predm3)\n",
    "ax.plot(y_test, y_test, 'r')\n",
    "ax.set(title='Actual vs Predicted price gradient boosting regression')\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576ce870-8b17-4328-88b2-e40bb2dd0320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN model\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "for num in range(1, 12):\n",
    "    knn_model = KNeighborsRegressor(n_neighbors=num).fit(Xs_train, y_train)\n",
    "    y_test_predm4 = knn_model.predict(Xs_test)\n",
    "    y_train_predm4 = knn_model.predict(Xs_train)\n",
    "    print(\"k = \", num)\n",
    "    print(\"Training MSE:\", round(mean_squared_error(y_train, y_train_predm4),4))\n",
    "    print(\"Validation MSE:\", round(mean_squared_error(y_test, y_test_predm4),4))\n",
    "    print(\"\\nTraining r2:\", round(r2_score(y_train, y_train_predm4),4))\n",
    "    print(\"Validation r2:\", round(r2_score(y_test, y_test_predm4),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4d67b9-c82f-486c-a682-2bae78fb4421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network model 1 sklearn\n",
    "from sklearn.neural_network  import MLPRegressor\n",
    "mlp = MLPRegressor(activation='relu', max_iter=1000)\n",
    "mlp.fit(Xs_train, y_train)\n",
    "y_test_predm5 = mlp.predict(Xs_test)\n",
    "y_train_predm5 = mlp.predict(Xs_train)\n",
    "print(\"Training MSE:\", round(mean_squared_error(y_train, y_train_predm5),4))\n",
    "print(\"Validation MSE:\", round(mean_squared_error(y_test, y_test_predm5),4))\n",
    "print(\"\\nTraining r2:\", round(r2_score(y_train, y_train_predm5),4))\n",
    "print(\"Validation r2:\", round(r2_score(y_test, y_test_predm5),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1a5254-55be-4fe5-a5f7-700946164bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(x=y_test, y=y_test_predm5)\n",
    "ax.plot(y_test, y_test, 'r')\n",
    "ax.set(title='Actual vs Predicted price neural network')\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae14324-f4c5-49da-b5b6-33081981adc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network model 2 keras\n",
    "from keras import models, layers, Input, Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation\n",
    "from keras.layers import BatchNormalization\n",
    "from keras import optimizers\n",
    "from keras import callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7734150c-d316-4140-815f-3528192364f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn2 = models.Sequential()\n",
    "nn2.add(layers.Dense(128, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "nn2.add(layers.Dense(256, activation='relu'))\n",
    "nn2.add(layers.Dense(128, activation='relu'))\n",
    "nn2.add(layers.Dense(1, activation='linear'))\n",
    "nn2.compile(loss='mean_squared_error',\n",
    "            optimizer='adam',\n",
    "            metrics=['mean_squared_error'])\n",
    "X2 = np.asarray(X_train).astype('float32')\n",
    "X3 = np.asarray(X_test).astype('float32')\n",
    "nn2.fit(X2,\n",
    "        y_train,\n",
    "        epochs=100,\n",
    "        batch_size=256,\n",
    "        validation_split = 0.1)\n",
    "y_test_predm6 = nn2.predict(X3)\n",
    "y_train_predm6 = nn2.predict(X2)\n",
    "print(\"Training MSE:\", round(mean_squared_error(y_train, y_train_predm6),4))\n",
    "print(\"Validation MSE:\", round(mean_squared_error(y_test, y_test_predm6),4))\n",
    "print(\"\\nTraining r2:\", round(r2_score(y_train, y_train_predm6),4))\n",
    "print(\"Validation r2:\", round(r2_score(y_test, y_test_predm6),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc59162-afa5-49eb-af7b-5856dcc955a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xgboost Regressor model\n",
    "import xgboost as xgb\n",
    "xgboost_model = xgb.XGBRegressor()\n",
    "\n",
    "# Fit the model on training data\n",
    "xgboost_model.fit(X_train, y_train)\n",
    "\n",
    "# Applying k-Fold Cross Validation\n",
    "kfold = KFold(n_splits=10)\n",
    "results = cross_val_score(xgboost_model, X, y, cv=kfold)\n",
    "print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "# Predict\n",
    "predict_train = xgboost_model.predict(X_train)\n",
    "\n",
    "# Validate\n",
    "predict_val = xgboost_model.predict(X_test)\n",
    "\n",
    "print(\"\\nTraining MSE:\", round(mean_squared_error(y_train, predict_train),4))\n",
    "print(\"Validation MSE:\", round(mean_squared_error(y_test, predict_val),4))\n",
    "print(\"\\nTraining r2:\", round(r2_score(y_train, predict_train),4))\n",
    "print(\"Validation r2:\", round(r2_score(y_test, predict_val),4))\n",
    "\n",
    "ax = sns.scatterplot(x=y_test, y=predict_val)\n",
    "ax.plot(y_test, y_test, 'r')\n",
    "ax.set(title='Actual vs Predicted price XGBoost regression')\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
